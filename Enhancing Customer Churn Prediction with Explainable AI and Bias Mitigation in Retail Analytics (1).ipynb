{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Load the dataset\n",
    "df = pd.read_csv('C:/Users/anjan/OneDrive/Desktop/MSC Project reference papers/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking null values\n",
    "df.isnull().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5131c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865ba7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e2efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type conversion\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].astype('category')\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors = 'coerce')\n",
    "df[['SeniorCitizen', 'TotalCharges']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there are any missing values were created\n",
    "df['TotalCharges'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the rows where the Column 'TotalCharges' has null values\n",
    "df = df.dropna(subset=['TotalCharges'])\n",
    "df['TotalCharges'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860bb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the column 'CustomerID' as its not useful\n",
    "df = df.drop('customerID', axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding categorical columns\n",
    "df.select_dtypes(include=['object', 'category']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding to change the categorical columns to Binary\n",
    "df_model = pd.get_dummies(df, drop_first=True)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb42e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_model.drop('Churn_Yes', axis=1)  # All features\n",
    "y = df_model['Churn_Yes']              # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f563d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb638a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# print('Original dataset shape %s' % Counter(y_train))\n",
    "# sm = SMOTE(random_state=42)\n",
    "# X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "# print('Resampled dataset shape %s' % Counter(y_train_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c7079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing XgBoost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize model\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Train\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SMOTE:# Initialize model\n",
    "# xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# # Train\n",
    "# xgb.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# # Predict\n",
    "# y_pred = xgb.predict(X_test)\n",
    "\n",
    "# # Evaluate\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e703e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# importance_scores = xgb.feature_importances_\n",
    "# indices = np.argsort(importance_scores)[::-1]\n",
    "# for f in range(15):\n",
    "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importance_scores[indices[f]]))\n",
    "# top_feature_names = [X_train.columns[i] for i in indices[:20]][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c170d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.barh(range(20), importance_scores[indices[:20][::-1]])  \n",
    "# plt.yticks(range(20), top_feature_names)\n",
    "# plt.xlabel(\"Importance Score\")\n",
    "# plt.title(\"Top 20 Feature Importances\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_features = [X_train.columns[i] for i in indices[:15]]  \n",
    "\n",
    "# Filter datasets to keep only top features\n",
    "#X_train_top = X_train[top_features]\n",
    "#X_test_top = X_test[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "#sm = SMOTE(random_state=42)\n",
    "#X_train_top_sm, y_train_sm = sm.fit_resample(X_train_top, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062cb9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Calculate scale_pos_weight from actual class imbalance\n",
    "neg, pos = np.bincount(y_train)\n",
    "scale = neg / pos\n",
    "\n",
    "# Step 2: Rebuild model with scale_pos_weight\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    scale_pos_weight=scale,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Fit on original X_train (NOT SMOTE)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predict and evaluate\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f34325",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for thresh in [0.45, 0.5, 0.55, 0.88, 0.85, 0.80, 0.78, 0.79]:\n",
    "    y_pred_thresh = (y_proba >= thresh).astype(int)\n",
    "    print(f\"\\nThreshold: {thresh}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_thresh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e19ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_08 = (y_proba >= 0.80).astype(int)\n",
    "print(classification_report(y_test, y_pred_08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59abe05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
